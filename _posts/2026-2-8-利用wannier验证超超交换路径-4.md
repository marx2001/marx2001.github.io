---
layout: post
title: "(原创自研)利用wannier验证超超交换路径(4)"
subtitle: "Experience Sharing"
background: '/img/bg-sci-note.jpg'
categories: sci-note
permalink: /sci-note_posts/20260208-super4
---

## <center>说明</center>

本篇文章是此系列最后一篇文章，提取跃迁矩阵元，将其对角化后量化d轨道和p轨道的分轨道的相对能量并画图。
文件路径：
```shell
/public/home/cssong/song/1mrx/9_single_layer/19_ReIrGe2S6/TcIrGeSe/3_static_band/4_wannier/ncl/20260207_detail/crystal_spiltl
```

## <center>代码</center>  

(1) 第一步
    
核心用途：从 Wannier90 的 wannier90_hr.dat 里提取每个原子对应的“局域在位（on-site）哈密顿量”子块，做本征分解得到“局域能级”（可理解为晶场/原子轨道能级的数值化近似），
并且用 wannier90.win 的投影顺序给这些能级打上 px/py/pz/dxy/... 之类的轨道标签，最后输出若干 CSV 统计文件。

该脚本通过读取三个关键文件构建材料模型：

wannier90_hr.dat（对应 --hr参数）：提取 R=(0,0,0) 的矩阵元，构建 on‑site 哈密顿量并做厄米化处理（0.5*(H0+H0†)）。

edges.csv（对应 --edges参数）：提供 Wannier 函数与原子/元素的归属关系，必须包含 m,n,atom m,atom n,elem m,elem n列；若同一 WF 被标记为不同原子或元素，脚本会报错并要
求修正一致性。

wannier90.win（对应 --win参数）：仅解析 begin projections…end projections块，获取各元素的投影轨道信息（支持自动将 d/p/s 展开为 5d/3p/1s）。

以上文件共同用于构建哈密顿量并关联轨道、原子与元素信息。

总的来说：专门用于分析Wannier函数局域能级的工具。它通过整合三份输入文件——hr.dat（提供哈密顿量矩阵元）、edges.csv（定义Wannier函数与原子的归属关系）和wannier90.win（规
定轨道的投影顺序）——来构建并分解每个原子附近的电子结构。

其核心计算流程分为六步：首先从哈密顿量中提取on-site相互作用部分；接着将Wannier函数按原子分组；然后依据投影信息为这些函数打上轨道标签；之后对每个原子的哈密顿量子块进行本
征分解，获得局域能级；再为每个能级标记出其主导轨道成分；最后还可选择性地进行能级配对诊断，以分析能级分裂特征。

脚本会输出三份CSV结果文件：levels.csv详细列出每个原子的所有能级及其主导轨道；pair_centers.csv提供能级配对的诊断信息；orbital_order.csv则汇总了每个原子各类轨道的最低
能量。总而言之，该工具将抽象的哈密顿量矩阵转化为清晰、按原子和轨道分解的能级图谱，极大地便利了后续的材料电子结构分析与可视化。

```python

#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import argparse
import csv
from pathlib import Path
import numpy as np
import pandas as pd


# =========================
# helpers: parse hr.dat
# =========================
def parse_hr_dat(hr_path: Path):
    lines = hr_path.read_text(encoding="utf-8", errors="ignore").splitlines()
    if len(lines) < 4:
        raise RuntimeError("hr.dat too short")
    num_wann = int(lines[1].strip())
    nrpts = int(lines[2].strip())

    degen = []
    idx = 3
    while len(degen) < nrpts:
        degen.extend([int(t) for t in lines[idx].split()])
        idx += 1
    rec_lines = lines[idx:]
    return num_wann, rec_lines


def build_H0(num_wann, rec_lines):
    H0 = np.zeros((num_wann, num_wann), dtype=np.complex128)
    for ln in rec_lines:
        if not ln.strip():
            continue
        toks = ln.split()
        if len(toks) < 7:
            continue
        Rx, Ry, Rz = int(toks[0]), int(toks[1]), int(toks[2])
        if (Rx, Ry, Rz) != (0, 0, 0):
            continue
        m = int(toks[3]) - 1
        n = int(toks[4]) - 1
        re0 = float(toks[5])
        im0 = float(toks[6])
        H0[m, n] = re0 + 1j * im0
    return 0.5 * (H0 + H0.conj().T)


# =========================
# helpers: parse edges.csv -> WF -> (atom_id, elem)
# =========================
def read_edges_wf_map(edges_path: Path):
    df = pd.read_csv(edges_path)
    needed = ["m", "n", "atom_m", "atom_n", "elem_m", "elem_n"]
    for c in needed:
        if c not in df.columns:
            raise RuntimeError(f"edges.csv missing required column: {c}")

    wf_to_pairs = {}
    for _, r in df.iterrows():
        m = int(r["m"]); n = int(r["n"])
        am = int(r["atom_m"]); an = int(r["atom_n"])
        em = str(r["elem_m"]); en = str(r["elem_n"])
        wf_to_pairs.setdefault(m, set()).add((am, em))
        wf_to_pairs.setdefault(n, set()).add((an, en))

    bad = []
    wf_map = {}
    for wf, s in wf_to_pairs.items():
        if len(s) != 1:
            bad.append((wf, sorted(list(s))))
        else:
            wf_map[wf] = next(iter(s))

    if bad:
        msg = ["[ERROR] Some WFs map to multiple (atom_id, elem) labels. Fix edges.csv labeling first."]
        for wf, pairs in bad[:50]:
            msg.append(f"  wf={wf}: {pairs}")
        raise RuntimeError("\n".join(msg))

    return wf_map


def atoms_by_element(wf_map, num_wann):
    elem_to_atoms = {}
    for wf in range(1, num_wann + 1):
        aid, elem = wf_map[wf]
        elem_to_atoms.setdefault(elem, set()).add(aid)
    return {e: sorted(list(s)) for e, s in elem_to_atoms.items()}


# =========================
# helpers: parse win projections (explicit order)
# =========================
def norm_orb(tok: str) -> str:
    t = tok.strip().lower()
    t = t.replace("dx2y2", "dx2-y2").replace("dx2_y2", "dx2-y2")
    t = t.replace("d(z2)", "dz2").replace("d(z^2)", "dz2").replace("d(z**2)", "dz2")
    t = t.replace("d(x2-y2)", "dx2-y2")
    return t


def expand_token(tok: str):
    t = norm_orb(tok)
    if t == "d":
        return ["dxy", "dyz", "dxz", "dz2", "dx2-y2"]
    if t == "p":
        return ["px", "py", "pz"]
    if t == "s":
        return ["s"]
    return [t]


def parse_win_projections(win_path: Path):
    lines = win_path.read_text(encoding="utf-8", errors="ignore").splitlines()
    in_proj = False
    proj_lines = []
    for ln in lines:
        s = ln.strip()
        low = s.lower()
        if low.startswith("begin projections"):
            in_proj = True
            continue
        if low.startswith("end projections"):
            in_proj = False
            continue
        if not in_proj:
            continue
        if (not s) or s.startswith("#") or s.startswith("!"):
            continue
        proj_lines.append(s)

    out = []
    for raw in proj_lines:
        if ":" not in raw:
            continue
        elem, rhs = raw.split(":", 1)
        elem = elem.strip()
        rhs = rhs.replace(",", " ").replace(";", " ")
        toks = [t for t in rhs.split() if t.strip()]
        orbs = []
        for t in toks:
            orbs += expand_token(t)
        out.append((elem, orbs))

    if not out:
        raise RuntimeError("[ERROR] No projections found in win. Check begin/end projections block.")
    return out


def build_wf_labels_from_win(proj_spec, elem_to_atoms, num_wann):
    """
    Construct expected WF label sequence in the SAME ordering as Wannier90 projections expansion.
    We assume SOC spinor duplication if num_wann == 2 * spatial_count.
    Return: list labels (1..num_wann): (atom_id, elem, orb)
    """
    spatial = []
    for elem, orbs in proj_spec:
        if elem not in elem_to_atoms:
            raise RuntimeError(f"[ERROR] win projections element '{elem}' not in edges elements {list(elem_to_atoms.keys())}")
        for aid in elem_to_atoms[elem]:
            for orb in orbs:
                spatial.append((aid, elem, orb))

    if len(spatial) == num_wann:
        return spatial, False
    if 2 * len(spatial) == num_wann:
        spinor = []
        for item in spatial:
            spinor.append(item)
            spinor.append(item)
        return spinor, True

    raise RuntimeError(
        "[ERROR] projection expansion count mismatch.\n"
        f"  spatial_count={len(spatial)}, num_wann={num_wann}\n"
        "Expected num_wann == spatial_count (no spinor) OR num_wann == 2*spatial_count (SOC spinor).\n"
    )


# =========================
# local diag + orbital labeling from basis
# =========================
def diag_local(H0, wf_list_1based):
    idx = [w - 1 for w in wf_list_1based]
    sub = H0[np.ix_(idx, idx)]
    evals, evecs = np.linalg.eigh(sub)
    order = np.argsort(np.real(evals))
    return np.real(evals[order]), evecs[:, order]


def try_pairs(evals_rel):
    if len(evals_rel) % 2 != 0:
        return []
    out = []
    for i in range(0, len(evals_rel), 2):
        e1 = float(evals_rel[i]); e2 = float(evals_rel[i + 1])
        out.append((0.5 * (e1 + e2), abs(e2 - e1), i, i + 1))
    return out


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--hr", default="wannier90_hr.dat")
    ap.add_argument("--edges", default="edges.csv")
    ap.add_argument("--win", default="wannier90.win")
    ap.add_argument("--Ef", type=float, default=0.0, help="output energies as E_rel = E - Ef (eV)")
    ap.add_argument("--out_prefix", default="cfFINAL")
    ap.add_argument("--pair_tol", type=float, default=0.02, help="warn if pair split > tol (eV)")
    args = ap.parse_args()

    hr_path = Path(args.hr)
    edges_path = Path(args.edges)
    win_path = Path(args.win)
    for p in [hr_path, edges_path, win_path]:
        if not p.exists():
            raise FileNotFoundError(p.resolve())

    num_wann, rec_lines = parse_hr_dat(hr_path)
    H0 = build_H0(num_wann, rec_lines)

    wf_map = read_edges_wf_map(edges_path)
    elem_to_atoms = atoms_by_element(wf_map, num_wann)

    proj_spec = parse_win_projections(win_path)
    expected_labels, spinor_dup = build_wf_labels_from_win(proj_spec, elem_to_atoms, num_wann)

    # Build WF groups per atom from edges (ground truth for which WF belongs to which atom)
    atom_to_wfs = {}
    atom_to_elem = {}
    for wf in range(1, num_wann + 1):
        aid, elem = wf_map[wf]
        atom_to_wfs.setdefault(aid, []).append(wf)
        atom_to_elem[aid] = elem
    for aid in atom_to_wfs:
        atom_to_wfs[aid] = sorted(atom_to_wfs[aid])

    # Now: assign each WF an orbital label by matching its position in the expected sequence.
    # This requires that the WF ordering produced by Wannier90 follows the projection expansion ordering.
    # We'll build wf_orb[wf] = orb_label.
    wf_orb = {}
    wf_expected_atom = {}
    for wf in range(1, num_wann + 1):
        aid_e, elem_e, orb_e = expected_labels[wf - 1]
        wf_expected_atom[wf] = (aid_e, elem_e)
        wf_orb[wf] = orb_e

    # Consistency check: WF->atom from edges should match expected atom from win ordering
    mism = []
    for wf in range(1, num_wann + 1):
        aid_true, elem_true = wf_map[wf]
        aid_e, elem_e = wf_expected_atom[wf]
        if (aid_true != aid_e) or (elem_true != elem_e):
            mism.append((wf, (aid_true, elem_true), (aid_e, elem_e)))
    if mism:
        # We do not abort; but we warn loudly because orbital labeling would be unreliable.
        print("[WARN] WF ordering does NOT match win projection expansion ordering for these WFs (first 20 shown):")
        for it in mism[:20]:
            print(f"  wf={it[0]} edges={it[1]} expected_from_win={it[2]}")
        print("[WARN] In this case, you must reorder WFs by parsing wout spread table or use a stricter mapping method.")
        # If this happens, stop now to avoid producing wrong orbital order.
        raise RuntimeError("WF ordering mismatch: cannot safely label orbitals from win ordering.")

    # Outputs
    out_levels = f"{args.out_prefix}_levels.csv"
    out_order = f"{args.out_prefix}_orbital_order.csv"
    out_pairs = f"{args.out_prefix}_pair_centers.csv"

    rows_levels = []
    rows_pairs = []
    lowest = {}  # (aid, elem, orb) -> lowest E_rel

    for aid in sorted(atom_to_wfs.keys()):
        elem = atom_to_elem[aid]
        wfs = atom_to_wfs[aid]
        evals, evecs = diag_local(H0, wfs)
        evals_rel = evals - args.Ef

        # basis orbital label list for this atom (same length as wfs)
        basis_orbs = [wf_orb[wf] for wf in wfs]

        for j in range(len(evals_rel)):
            c2 = np.abs(evecs[:, j]) ** 2
            # orbital weight = sum |c_i|^2 over basis functions with same orb label
            orb_w = {}
            for i, orb in enumerate(basis_orbs):
                orb_w[orb] = orb_w.get(orb, 0.0) + float(c2[i])
            dom_orb = max(orb_w.keys(), key=lambda k: orb_w[k])
            dom_w = orb_w[dom_orb]

            rows_levels.append({
                "atom_id": aid,
                "elem": elem,
                "n_wf": len(wfs),
                "level_index": j + 1,
                "E_rel": float(evals_rel[j]),
                "dominant_orb": dom_orb,
                "dominant_w": float(dom_w)
            })

            key = (aid, elem, dom_orb)
            lowest[key] = min(lowest.get(key, 1e30), float(evals_rel[j]))

        # pair diagnostics
        pairs = try_pairs(evals_rel)
        for pi, (center, split, i1, i2) in enumerate(pairs, start=1):
            warn = int(split > args.pair_tol)
            # label by combined weights
            c2 = (np.abs(evecs[:, i1]) ** 2 + np.abs(evecs[:, i2]) ** 2)
            orb_w = {}
            for i, orb in enumerate(basis_orbs):
                orb_w[orb] = orb_w.get(orb, 0.0) + float(c2[i])
            dom_orb = max(orb_w.keys(), key=lambda k: orb_w[k])
            dom_w = orb_w[dom_orb]

            rows_pairs.append({
                "atom_id": aid,
                "elem": elem,
                "n_wf": len(wfs),
                "pair_index": pi,
                "center_rel": float(center),
                "split": float(split),
                "dominant_orb_pair": dom_orb,
                "dominant_w_pair": float(dom_w),
                "warn_split_gt_tol": warn
            })

    pd.DataFrame(rows_levels).to_csv(out_levels, index=False)
    pd.DataFrame(rows_pairs).to_csv(out_pairs, index=False)

    out_rows = []
    for (aid, elem, orb), E0 in sorted(lowest.items(), key=lambda x: (x[0][1], x[0][0], x[1], x[0][2])):
        out_rows.append({
            "atom_id": aid, "elem": elem, "orbital": orb,
            "lowest_E_rel": float(E0)
        })
    pd.DataFrame(out_rows).to_csv(out_order, index=False)

    print("[OK] Done.")
    print(f"  spinor_dup = {spinor_dup}")
    print(f"  wrote: {out_levels}")
    print(f"  wrote: {out_pairs}")
    print(f"  wrote: {out_order}")
    print("Notes:")
    print("  - This route labels orbitals from win projection expansion order; it is stable and does NOT depend on chk/amn.")
    print("  - If you are FM+SOC (TR broken), pair_centers are diagnostic only; do not treat them as Kramers by default.")


if __name__ == "__main__":
    main()


```

使用方法：

```shell
python cf_final_hr_win_edges.py --Ef -1.4631 --out_prefix cfA2
```

(2) 第二步


这是一个用于分析材料中元素局域能级分布的Python脚本。其核心功能是对前序脚本（如 cf_final hr_win_edges.py）生成的 *_levels.csv文件进行高阶统计分析。

脚本首先对原始数据进行清洗，过滤掉主导轨道标签不可靠的能级（如轨道权重过低或为空），确保分析质量。随后，按“元素-主导轨道”组合进行分组，计算每个组内能级能量的详细统计量，
包括均值、标准差、分位数等。最重要的，脚本会汇总每个元素在不同轨道上的中位数能级，并通过计算其极差，生成一个衡量“晶场分裂强度”或“轨道能级展开”的实用摘要。

最终，脚本会输出三个CSV文件：一份包含所有有效能级的详细长表、一份每个元素-轨道组合的统计量表，以及一份汇总了各元素轨道能级展开范围的核心摘要，从而将原子尺度的复杂数据提炼
为元素层面的清晰物理图像。

```python

#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import argparse
from pathlib import Path
import pandas as pd
import numpy as np


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--levels", default="cfA2_levels.csv", help="*_levels.csv from the CF script")
    ap.add_argument("--out_prefix", default="cf_elem", help="output prefix")
    ap.add_argument("--min_dom_w", type=float, default=0.20,
                    help="discard levels whose dominant_w < this threshold (label too mixed)")
    args = ap.parse_args()

    levels_path = Path(args.levels)
    if not levels_path.exists():
        raise FileNotFoundError(levels_path.resolve())

    df = pd.read_csv(levels_path)

    need = {"atom_id", "elem", "n_wf", "level_index", "E_rel", "dominant_orb", "dominant_w"}
    miss = need - set(df.columns)
    if miss:
        raise RuntimeError(f"levels file missing columns: {sorted(list(miss))}")

    # clean
    df["dominant_orb"] = df["dominant_orb"].astype(str).str.strip()
    df = df[df["dominant_orb"] != ""].copy()

    # filter mixed labels
    df_f = df[df["dominant_w"] >= args.min_dom_w].copy()

    # long table output
    long_out = f"{args.out_prefix}_elem_orb_levels_long.csv"
    df_f.to_csv(long_out, index=False)

    # base stats
    stats = (
        df_f.groupby(["elem", "dominant_orb"])["E_rel"]
        .agg(count="count", mean="mean", std="std", min="min", max="max")
        .reset_index()
    )

    # quantiles (robust way)
    qs = (
        df_f.groupby(["elem", "dominant_orb"])["E_rel"]
        .quantile([0.25, 0.50, 0.75])
        .unstack(level=-1)
        .reset_index()
        .rename(columns={0.25: "q25", 0.50: "q50", 0.75: "q75"})
    )

    stats = stats.merge(qs, on=["elem", "dominant_orb"], how="left")

    # per-element splitting summary (range of orbital medians)
    med = stats.pivot_table(index="elem", columns="dominant_orb", values="q50", aggfunc="first")

    elem_split = []
    for elem in med.index:
        vals = med.loc[elem].dropna().to_numpy()
        if len(vals) == 0:
            continue
        elem_split.append({
            "elem": elem,
            "orbital_median_range": float(vals.max() - vals.min()),
            "orbital_median_min": float(vals.min()),
            "orbital_median_max": float(vals.max()),
            "n_orbitals": int(len(vals))
        })
    elem_split_df = pd.DataFrame(elem_split).sort_values(["elem"])

    # write outputs
    stats_out = f"{args.out_prefix}_elem_orb_stats.csv"
    split_out = f"{args.out_prefix}_elem_splitting_summary.csv"

    stats.sort_values(["elem", "dominant_orb"]).to_csv(stats_out, index=False)
    elem_split_df.to_csv(split_out, index=False)

    print("[OK] wrote:")
    print(" ", long_out)
    print(" ", stats_out)
    print(" ", split_out)
    print(f"[INFO] kept {len(df_f)} / {len(df)} levels (min_dom_w={args.min_dom_w})")

    if len(elem_split_df) > 0:
        print("\n[Summary] per-element orbital median range (q50 max-min):")
        for _, r in elem_split_df.iterrows():
            print(f"  {r['elem']}: range={r['orbital_median_range']:.4f} eV over {r['n_orbitals']} orbitals")


if __name__ == "__main__":
    main()


```


使用方法：

```python

python collect_elem_cf_stats.py --levels cfA2_levels.csv --out_prefix elemCF --min_dom_w 0.20

```

(3) 第三步

该脚本（cfFINAL_export_fullweights.py）在材料电子结构分析中实现了关键增强。它首先读取三个必要文件：wannier90_hr.dat（构建on-site哈密顿量）、edges.csv（建立Wannier
函数到原子的唯一映射）和wannier90.win（确定投影轨道顺序），并严格校验WF顺序与投影顺序的一致性以保证后续标签准确。

其核心计算分为两步：对每个原子的on-site哈密顿量子块进行对角化，得到局域能级；然后，对每条能级的本征态，计算其在所有基轨道（如px、py、pz、dxy等）上的详细权重分布。这是相
较于旧版工具的最大提升——旧版仅输出主导轨道，而新版会导出所有轨道的精确占比。

脚本最终输出三个CSV文件，其中最重要的*_levels_fullweights.csv文件完整记录了每条能级的全轨道权重。这使得用户可以直接提取特定元素（如硒Se）的所有px、py、pz轨道权重，进
而进行加权的分布统计、绘制能级展开图等深入分析，而不再局限于之前仅基于主导轨道的简化统计。


```python

#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import argparse
from pathlib import Path
import numpy as np
import pandas as pd


def parse_hr_dat(hr_path: Path):
    lines = hr_path.read_text(encoding="utf-8", errors="ignore").splitlines()
    num_wann = int(lines[1].strip())
    nrpts = int(lines[2].strip())
    degen = []
    idx = 3
    while len(degen) < nrpts:
        degen.extend([int(t) for t in lines[idx].split()])
        idx += 1
    rec_lines = lines[idx:]
    return num_wann, rec_lines


def build_H0(num_wann, rec_lines):
    H0 = np.zeros((num_wann, num_wann), dtype=np.complex128)
    for ln in rec_lines:
        if not ln.strip():
            continue
        toks = ln.split()
        if len(toks) < 7:
            continue
        Rx, Ry, Rz = int(toks[0]), int(toks[1]), int(toks[2])
        if (Rx, Ry, Rz) != (0, 0, 0):
            continue
        m = int(toks[3]) - 1
        n = int(toks[4]) - 1
        H0[m, n] = float(toks[5]) + 1j * float(toks[6])
    return 0.5 * (H0 + H0.conj().T)


def read_edges_wf_map(edges_path: Path):
    df = pd.read_csv(edges_path)
    needed = ["m", "n", "atom_m", "atom_n", "elem_m", "elem_n"]
    for c in needed:
        if c not in df.columns:
            raise RuntimeError(f"edges.csv missing required column: {c}")

    wf_to_pairs = {}
    for _, r in df.iterrows():
        m = int(r["m"]); n = int(r["n"])
        am = int(r["atom_m"]); an = int(r["atom_n"])
        em = str(r["elem_m"]); en = str(r["elem_n"])
        wf_to_pairs.setdefault(m, set()).add((am, em))
        wf_to_pairs.setdefault(n, set()).add((an, en))

    bad = []
    wf_map = {}
    for wf, s in wf_to_pairs.items():
        if len(s) != 1:
            bad.append((wf, sorted(list(s))))
        else:
            wf_map[wf] = next(iter(s))
    if bad:
        msg = ["[ERROR] WF->(atom,elem) inconsistent in edges.csv"]
        for wf, pairs in bad[:30]:
            msg.append(f"  wf={wf}: {pairs}")
        raise RuntimeError("\n".join(msg))
    return wf_map


def atoms_by_element(wf_map, num_wann):
    elem_to_atoms = {}
    for wf in range(1, num_wann + 1):
        aid, elem = wf_map[wf]
        elem_to_atoms.setdefault(elem, set()).add(aid)
    return {e: sorted(list(s)) for e, s in elem_to_atoms.items()}


def norm_orb(tok: str) -> str:
    t = tok.strip().lower()
    t = t.replace("dx2y2", "dx2-y2").replace("dx2_y2", "dx2-y2")
    t = t.replace("d(z2)", "dz2").replace("d(z^2)", "dz2").replace("d(z**2)", "dz2")
    t = t.replace("d(x2-y2)", "dx2-y2")
    return t


def expand_token(tok: str):
    t = norm_orb(tok)
    if t == "d":
        return ["dxy", "dyz", "dxz", "dz2", "dx2-y2"]
    if t == "p":
        return ["px", "py", "pz"]
    if t == "s":
        return ["s"]
    return [t]


def parse_win_projections(win_path: Path):
    lines = win_path.read_text(encoding="utf-8", errors="ignore").splitlines()
    in_proj = False
    proj_lines = []
    for ln in lines:
        s = ln.strip()
        low = s.lower()
        if low.startswith("begin projections"):
            in_proj = True
            continue
        if low.startswith("end projections"):
            in_proj = False
            continue
        if not in_proj:
            continue
        if (not s) or s.startswith("#") or s.startswith("!"):
            continue
        proj_lines.append(s)

    out = []
    for raw in proj_lines:
        if ":" not in raw:
            continue
        elem, rhs = raw.split(":", 1)
        elem = elem.strip()
        rhs = rhs.replace(",", " ").replace(";", " ")
        toks = [t for t in rhs.split() if t.strip()]
        orbs = []
        for t in toks:
            orbs += expand_token(t)
        out.append((elem, orbs))
    if not out:
        raise RuntimeError("[ERROR] No projections in win.")
    return out


def build_expected_labels(proj_spec, elem_to_atoms, num_wann):
    spatial = []
    for elem, orbs in proj_spec:
        if elem not in elem_to_atoms:
            raise RuntimeError(f"[ERROR] elem {elem} in win not found in edges-derived elements {list(elem_to_atoms.keys())}")
        for aid in elem_to_atoms[elem]:
            for orb in orbs:
                spatial.append((aid, elem, orb))
    if len(spatial) == num_wann:
        return spatial, False
    if 2 * len(spatial) == num_wann:
        spinor = []
        for x in spatial:
            spinor.append(x); spinor.append(x)
        return spinor, True
    raise RuntimeError(f"[ERROR] projection count mismatch: spatial={len(spatial)} num_wann={num_wann}")


def diag_local(H0, wf_list_1based):
    idx = [w - 1 for w in wf_list_1based]
    sub = H0[np.ix_(idx, idx)]
    evals, evecs = np.linalg.eigh(sub)
    order = np.argsort(np.real(evals))
    return np.real(evals[order]), evecs[:, order]


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--hr", default="wannier90_hr.dat")
    ap.add_argument("--edges", default="edges.csv")
    ap.add_argument("--win", default="wannier90.win")
    ap.add_argument("--Ef", type=float, default=0.0)
    ap.add_argument("--out_prefix", default="cfFW")
    args = ap.parse_args()

    hr_path = Path(args.hr)
    edges_path = Path(args.edges)
    win_path = Path(args.win)
    for p in [hr_path, edges_path, win_path]:
        if not p.exists():
            raise FileNotFoundError(p.resolve())

    num_wann, rec_lines = parse_hr_dat(hr_path)
    H0 = build_H0(num_wann, rec_lines)

    wf_map = read_edges_wf_map(edges_path)
    elem_to_atoms = atoms_by_element(wf_map, num_wann)

    proj_spec = parse_win_projections(win_path)
    expected_labels, spinor_dup = build_expected_labels(proj_spec, elem_to_atoms, num_wann)

    # verify WF ordering matches expected atom labels
    mism = []
    for wf in range(1, num_wann + 1):
        aid_true, elem_true = wf_map[wf]
        aid_e, elem_e, _ = expected_labels[wf - 1]
        if (aid_true != aid_e) or (elem_true != elem_e):
            mism.append((wf, (aid_true, elem_true), (aid_e, elem_e)))
    if mism:
        print("[WARN] WF ordering mismatch with win expansion ordering; cannot label safely.")
        for it in mism[:20]:
            print("  wf", it[0], "edges", it[1], "expected", it[2])
        raise RuntimeError("WF ordering mismatch; stop.")

    # WF -> orbital label (basis orbital)
    wf_orb = {wf: expected_labels[wf - 1][2] for wf in range(1, num_wann + 1)}

    # group WFs by atom
    atom_to_wfs = {}
    atom_to_elem = {}
    for wf in range(1, num_wann + 1):
        aid, elem = wf_map[wf]
        atom_to_wfs.setdefault(aid, []).append(wf)
        atom_to_elem[aid] = elem
    for aid in atom_to_wfs:
        atom_to_wfs[aid] = sorted(atom_to_wfs[aid])

    # outputs
    out_levels = f"{args.out_prefix}_levels.csv"
    out_full = f"{args.out_prefix}_levels_fullweights.csv"
    out_order = f"{args.out_prefix}_orbital_order.csv"

    rows_levels = []
    rows_full = []
    lowest = {}

    for aid in sorted(atom_to_wfs.keys()):
        elem = atom_to_elem[aid]
        wfs = atom_to_wfs[aid]
        evals, evecs = diag_local(H0, wfs)
        evals_rel = evals - args.Ef

        basis_orbs = [wf_orb[wf] for wf in wfs]
        unique_orbs = sorted(list(set(basis_orbs)))

        for j in range(len(evals_rel)):
            c2 = np.abs(evecs[:, j])**2
            orb_w = {o: 0.0 for o in unique_orbs}
            for i, o in enumerate(basis_orbs):
                orb_w[o] += float(c2[i])

            dom_orb = max(orb_w.keys(), key=lambda k: orb_w[k])
            dom_w = orb_w[dom_orb]

            rows_levels.append({
                "atom_id": aid, "elem": elem, "n_wf": len(wfs),
                "level_index": j+1, "E_rel": float(evals_rel[j]),
                "dominant_orb": dom_orb, "dominant_w": float(dom_w)
            })

            r = {"atom_id": aid, "elem": elem, "n_wf": len(wfs),
                 "level_index": j+1, "E_rel": float(evals_rel[j])}
            # add all orbital weights as columns
            for o in unique_orbs:
                r[f"w_{o}"] = float(orb_w[o])
            rows_full.append(r)

            key = (aid, elem, dom_orb)
            lowest[key] = min(lowest.get(key, 1e30), float(evals_rel[j]))

    pd.DataFrame(rows_levels).to_csv(out_levels, index=False)
    pd.DataFrame(rows_full).to_csv(out_full, index=False)

    out_rows = []
    for (aid, elem, orb), E0 in sorted(lowest.items(), key=lambda x: (x[0][1], x[0][0], x[0][2])):
        out_rows.append({"atom_id": aid, "elem": elem, "orbital": orb, "lowest_E_rel": float(E0)})
    pd.DataFrame(out_rows).to_csv(out_order, index=False)

    print("[OK] wrote:")
    print(" ", out_levels)
    print(" ", out_full)
    print(" ", out_order)
    print("[INFO] spinor_dup =", spinor_dup)


if __name__ == "__main__":
    main()


```

```shell

python cfFINAL_export_fullweights.py --out_prefix cfFW

```

(4) 第四步


collect_elem_orbital_distributions.py脚本是用于分析材料中元素轨道能量分布的专业工具。其核心功能是基于包含全轨道权重的能级数据（*_levels_fullweights.csv），对每个元
素的各个轨道（如 Se 的 px、py、pz）进行加权统计，这完美解决了你之前提出的“分析Se的px/py/pz整体分布”的需求。

具体而言，它对每个元素和轨道（如 w_px）执行以下计算：首先，将每条能级的相对能量 E_rel视为样本值，并将其在该轨道上的权重 w_orb作为样本权重；接着，过滤掉权重过小的噪声数
据；然后，计算加权平均值、标准差、分位数等统计量；最后，生成加权的能量分布直方图数据。

脚本默认输出两个CSV文件：一个汇总每个元素-轨道组合的加权统计数据（*_weighted_stats.csv），另一个则提供用于绘制分布曲线或热图的直方图数据点（*_hist.csv）。

与此前按主导轨道进行“硬分类”的脚本 collect_elem_cf_stats.py不同，本脚本利用全轨道权重进行“软分解”统计，能更精确地刻画每个轨道对整体能级的贡献分布。

```python

#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import argparse
from pathlib import Path
import numpy as np
import pandas as pd


def weighted_quantile(values, weights, qs):
    """values, weights: 1D arrays; qs in [0,1]"""
    values = np.asarray(values, dtype=float)
    weights = np.asarray(weights, dtype=float)
    m = (weights > 0) & np.isfinite(values)
    values = values[m]; weights = weights[m]
    if len(values) == 0:
        return [np.nan for _ in qs]
    s = np.argsort(values)
    v = values[s]; w = weights[s]
    cw = np.cumsum(w)
    cw /= cw[-1]
    return [float(np.interp(q, cw, v)) for q in qs]


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--full", default="cfFW_levels_fullweights.csv",
                    help="*_levels_fullweights.csv")
    ap.add_argument("--out_prefix", default="elemDist")
    ap.add_argument("--bins", type=int, default=60)
    ap.add_argument("--emin", type=float, default=None)
    ap.add_argument("--emax", type=float, default=None)
    ap.add_argument("--min_weight", type=float, default=1e-6,
                    help="discard contributions with orbital weight < this")
    args = ap.parse_args()

    p = Path(args.full)
    if not p.exists():
        raise FileNotFoundError(p.resolve())

    df = pd.read_csv(p)

    # find weight columns
    wcols = [c for c in df.columns if c.startswith("w_")]
    if not wcols:
        raise RuntimeError("No w_* columns found. Use cfFINAL_export_fullweights.py first.")

    # energy range
    E = df["E_rel"].to_numpy(dtype=float)
    emin = np.nanmin(E) if args.emin is None else args.emin
    emax = np.nanmax(E) if args.emax is None else args.emax
    edges = np.linspace(emin, emax, args.bins + 1)

    stats_rows = []
    hist_rows = []

    # for each element + orbital: treat each level contributes weight w_orb at energy E
    for elem in sorted(df["elem"].unique()):
        sub = df[df["elem"] == elem].copy()
        Es = sub["E_rel"].to_numpy(dtype=float)

        for wc in wcols:
            orb = wc[2:]  # remove "w_"
            ws = sub[wc].to_numpy(dtype=float)

            m = ws >= args.min_weight
            if m.sum() == 0:
                continue

            v = Es[m]
            w = ws[m]

            wsum = float(w.sum())
            mean = float(np.sum(w * v) / wsum)
            var = float(np.sum(w * (v - mean)**2) / wsum)
            std = float(np.sqrt(var))

            q25, q50, q75 = weighted_quantile(v, w, [0.25, 0.50, 0.75])
            vmin = float(np.min(v))
            vmax = float(np.max(v))

            stats_rows.append({
                "elem": elem, "orbital": orb,
                "weight_sum": wsum,
                "wmean_E": mean,
                "wstd_E": std,
                "wmin_E": vmin,
                "wmax_E": vmax,
                "wq25_E": q25,
                "wq50_E": q50,
                "wq75_E": q75
            })

            # weighted histogram
            hist, _ = np.histogram(v, bins=edges, weights=w)
            centers = 0.5 * (edges[:-1] + edges[1:])
            for x, h in zip(centers, hist):
                hist_rows.append({
                    "elem": elem, "orbital": orb,
                    "E_center": float(x),
                    "weighted_count": float(h)
                })

    stats_df = pd.DataFrame(stats_rows).sort_values(["elem", "orbital"])
    hist_df = pd.DataFrame(hist_rows).sort_values(["elem", "orbital", "E_center"])

    out_stats = f"{args.out_prefix}_elem_orb_weighted_stats.csv"
    out_hist = f"{args.out_prefix}_elem_orb_hist.csv"
    stats_df.to_csv(out_stats, index=False)
    hist_df.to_csv(out_hist, index=False)

    print("[OK] wrote:")
    print(" ", out_stats)
    print(" ", out_hist)
    print(f"[INFO] energy range: [{emin:.6f}, {emax:.6f}] eV, bins={args.bins}")


if __name__ == "__main__":
    main()


```

使用方法：

```shell

python collect_elem_orbital_distributions.py --full cfFW_levels_fullweights.csv --out_prefix elemCFdist --bins 60.

```


(5) 第五步 绘图

配套的绘图工具，用于将前序统计分析的结果进行可视化。

plot_elem_level_diagram.py​ 用于绘制元素的轨道能级示意图。它读取包含加权统计量（如中位数、四分位数）的文件，为指定元素的每个轨道绘制一条以加权中位能量为中心的水平线
段，并可选择添加四分位距区间以示意能级分布宽度。其产出类似一张简明的“能级图”，直观展示各轨道能量的中心位置与离散程度。

plot_elem_orb_distributions.py​ 则用于绘制元素-轨道的能量分布曲线图。它基于直方图数据文件，为指定元素的每个轨道绘制一条完整的分布曲线，横轴为能量，纵轴为加权强度，从而
完整呈现每个轨道在能量空间中的分布形状、峰位和展宽。

两者的核心区别在于信息压缩程度：前者将每个轨道的信息压缩为一个代表性能级（可带误差棒），产出示意图；后者则保留并展示完整的分布轮廓，产出细节曲线图。它们从不同维度呈现同一
组数据，共同服务于对材料中元素局域电子结构的深入理解与展示。

```python

#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import argparse
from pathlib import Path
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt


def orbital_sort_key(orb):
    # order p then d if mixed; within sets use common order
    p_order = ["px", "py", "pz"]
    d_order = ["dxy", "dyz", "dxz", "dz2", "dx2-y2"]
    if orb in p_order:
        return (0, p_order.index(orb))
    if orb in d_order:
        return (1, d_order.index(orb))
    return (2, orb)


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--stats", default="elemCFdist_elem_orb_weighted_stats.csv")
    ap.add_argument("--elem", required=True, help="Element symbol, e.g. Se / Tc / Ir / Ge")
    ap.add_argument("--out", default=None, help="Output image path (png/pdf). If omitted, auto name.")
    ap.add_argument("--title", default=None)
    ap.add_argument("--band", action="store_true",
                    help="Draw q25-q75 interval as a vertical band around the median energy.")
    ap.add_argument("--ymin", type=float, default=None)
    ap.add_argument("--ymax", type=float, default=None)
    ap.add_argument("--dpi", type=int, default=300)
    args = ap.parse_args()

    p = Path(args.stats)
    if not p.exists():
        raise FileNotFoundError(p.resolve())

    df = pd.read_csv(p)
    need = {"elem", "orbital", "wq25_E", "wq50_E", "wq75_E", "weight_sum"}
    miss = need - set(df.columns)
    if miss:
        raise RuntimeError(f"Missing columns in stats csv: {sorted(list(miss))}")

    sub = df[df["elem"].astype(str).str.strip() == args.elem].copy()
    if len(sub) == 0:
        raise RuntimeError(f"No rows for elem={args.elem} in {p.name}")

    sub["orbital"] = sub["orbital"].astype(str).str.strip()
    sub = sub.sort_values("orbital", key=lambda s: s.map(orbital_sort_key))

    orbs = sub["orbital"].tolist()
    y50 = sub["wq50_E"].to_numpy(float)
    y25 = sub["wq25_E"].to_numpy(float)
    y75 = sub["wq75_E"].to_numpy(float)

    # x positions: 1..N
    xs = np.arange(1, len(orbs) + 1)

    plt.figure(figsize=(4.8, 5.5))

    # draw median level as horizontal line segments
    for x, e in zip(xs, y50):
        plt.hlines(e, x - 0.35, x + 0.35, linewidth=2)

    # optional: draw q25-q75 as vertical band
    if args.band:
        for x, lo, hi in zip(xs, y25, y75):
            plt.vlines(x, lo, hi, linewidth=2, alpha=0.7)

    plt.xticks(xs, orbs, rotation=0)
    plt.ylabel("Energy (E_rel) [eV]")

    ttl = args.title if args.title else f"{args.elem}: orbital level positions (weighted q50)"
    plt.title(ttl)

    if args.ymin is not None or args.ymax is not None:
        plt.ylim(args.ymin, args.ymax)

    plt.tight_layout()

    out = args.out if args.out else f"{args.elem}_level_diagram.png"
    plt.savefig(out, dpi=args.dpi)
    print("[OK] saved:", out)


if __name__ == "__main__":
    main()


```

```python

#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import argparse
from pathlib import Path
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt


def orbital_sort_key(orb):
    p_order = ["px", "py", "pz"]
    d_order = ["dxy", "dyz", "dxz", "dz2", "dx2-y2"]
    if orb in p_order:
        return (0, p_order.index(orb))
    if orb in d_order:
        return (1, d_order.index(orb))
    return (2, orb)


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--hist", default="elemCFdist_elem_orb_hist.csv")
    ap.add_argument("--elem", required=True)
    ap.add_argument("--out", default=None)
    ap.add_argument("--title", default=None)
    ap.add_argument("--normalize", action="store_true",
                    help="Normalize each orbital curve by its total area (sum of weighted_count).")
    ap.add_argument("--xmin", type=float, default=None)
    ap.add_argument("--xmax", type=float, default=None)
    ap.add_argument("--dpi", type=int, default=300)
    args = ap.parse_args()

    p = Path(args.hist)
    if not p.exists():
        raise FileNotFoundError(p.resolve())

    df = pd.read_csv(p)
    need = {"elem", "orbital", "E_center", "weighted_count"}
    miss = need - set(df.columns)
    if miss:
        raise RuntimeError(f"Missing columns in hist csv: {sorted(list(miss))}")

    sub = df[df["elem"].astype(str).str.strip() == args.elem].copy()
    if len(sub) == 0:
        raise RuntimeError(f"No rows for elem={args.elem} in {p.name}")

    sub["orbital"] = sub["orbital"].astype(str).str.strip()

    orbs = sorted(sub["orbital"].unique(), key=orbital_sort_key)

    plt.figure(figsize=(5.6, 4.8))

    for orb in orbs:
        s = sub[sub["orbital"] == orb].sort_values("E_center")
        x = s["E_center"].to_numpy(float)
        y = s["weighted_count"].to_numpy(float)

        if args.normalize:
            area = float(np.sum(y))
            if area > 0:
                y = y / area

        plt.plot(x, y, linewidth=1.8, label=orb)

    plt.xlabel("Energy (E_rel) [eV]")
    plt.ylabel("Weighted intensity" + (" (normalized)" if args.normalize else ""))

    ttl = args.title if args.title else f"{args.elem}: orbital-weighted energy distributions"
    plt.title(ttl)

    if args.xmin is not None or args.xmax is not None:
        plt.xlim(args.xmin, args.xmax)

    plt.legend()
    plt.tight_layout()

    out = args.out if args.out else f"{args.elem}_orbital_distributions.png"
    plt.savefig(out, dpi=args.dpi)
    print("[OK] saved:", out)


if __name__ == "__main__":
    main()


```

```shell

python plot_elem_level_diagram.py --stats elemCFdist_elem_orb_weighted_stats.csv --elem Se --out Se_levels.png
python plot_elem_level_diagram.py --stats elemCFdist_elem_orb_weighted_stats.csv --elem Tc --out Tc_levels.png
python plot_elem_level_diagram.py --stats elemCFdist_elem_orb_weighted_stats.csv --elem Ir --out Ir_levels.png
python plot_elem_level_diagram.py --stats elemCFdist_elem_orb_weighted_stats.csv --elem Ge --out Ge_levels.png


python plot_elem_orb_distributions.py --hist elemCFdist_elem_orb_hist.csv --elem Se --out Se_dist.png
python plot_elem_orb_distributions.py --hist elemCFdist_elem_orb_hist.csv --elem Tc --out Tc_dist.png
python plot_elem_orb_distributions.py --hist elemCFdist_elem_orb_hist.csv --elem Ir --out Ir_dist.png
python plot_elem_orb_distributions.py --hist elemCFdist_elem_orb_hist.csv --elem Ge --out Ge_dist.png

```





